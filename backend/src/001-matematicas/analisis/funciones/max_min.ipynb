{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Extremos de una función</center>\n",
    "\n",
    "> Conocimientos necesarios:\n",
    "- [Derivadas](https://github.com/mondeja/fullstack/blob/master/backend/src/001-matematicas/analisis/funciones/derivadas.ipynb)\n",
    "\n",
    "Los **máximos** y **mínimos** de una función, conocidos colectivamente como extremos de una función, son los valores más grandes (máximos) o más pequeños (mínimos), que toma una función en un punto situado ya sea dentro de una región en particular de la curva (extremo local) o en el dominio de la función en su totalidad (extremo global o absoluto).\n",
    "\n",
    "![Máximos y mínimos de una función](https://s20.postimg.org/njxqfh4i5/max_min_function.jpg)\n",
    "\n",
    "## Cálculo del mínimo y el máximo\n",
    "\n",
    "> Para una parábola ćoncava (abierta hacia arriba), calcular sus máximos es un problema, pues tenderán a infinito y viceversa para las convexas.\n",
    "\n",
    "### Programáticamente\n",
    "Podemos usar la función [`fmin()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin.html) de Scipy para calcular el mínimo. Si queremos calcular el máximo simplemente lo calculamos para la inversa de la función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -75.000000\n",
      "         Iterations: 19\n",
      "         Function evaluations: 38\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -75.000000\n",
      "         Iterations: 22\n",
      "         Function evaluations: 44\n",
      "[-75.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f13b1324eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =======================    Mínimo    ==========================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import fmin  # Función para calcular el mínimo de una función\n",
    "\n",
    "# Función\n",
    "f = lambda x: x**2 + 10*x -50\n",
    "\n",
    "# Rangos\n",
    "x = np.linspace(-100, 101, 200)\n",
    "y = f(x)  # Función f(x)\n",
    "\n",
    "# Mínimos relativos\n",
    "x0 = -10  # Empezando desde x=-10\n",
    "xmin0 = fmin(f, x0)\n",
    "\n",
    "x1 = 5  # Empezando desde x = 5\n",
    "xmin1 = fmin(f, x1)\n",
    "print(f(xmin1))\n",
    "\n",
    "# --------------------------------------\n",
    "\n",
    "# Instanciamos figura\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "plt.xlim(-40, 40)\n",
    "plt.ylim(-200, 200)\n",
    "\n",
    "# Pinta la gráfica\n",
    "ax.plot(x, y)\n",
    "# Pinta el mínimo encontrado empezando desde x0\n",
    "ax.plot(xmin0, f(xmin0), 'ro')\n",
    "# Pinta el mínimo encontrado empezando desde x1\n",
    "ax.plot(x1, f(x1), 'ro')\n",
    "\n",
    "\n",
    "# Líneas de ejes 0\n",
    "ax.axhline(y=0, color='k')\n",
    "ax.axvline(x=0, color='k')\n",
    "\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes observar, el método anterior opera resolviendo muchas veces la función para distintos valores de $x$ en su búsqueda del mínimo valor de $y$. Algo parecido sería la siguiente implementación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 0.900000\ty_inicial = -40.190000\n",
      "x: 0.800000\ty_inicial = -41.360000\n",
      "x: 0.700000\ty_inicial = -42.510000\n",
      "x: 0.600000\ty_inicial = -43.640000\n",
      "x: 0.500000\ty_inicial = -44.750000\n",
      "x: 0.400000\ty_inicial = -45.840000\n",
      "x: 0.300000\ty_inicial = -46.910000\n",
      "x: 0.200000\ty_inicial = -47.960000\n",
      "x: 0.100000\ty_inicial = -48.990000\n",
      "x: 0.000000\ty_inicial = -50.000000\n",
      "x: -0.100000\ty_inicial = -50.990000\n",
      "x: -0.200000\ty_inicial = -51.960000\n",
      "x: -0.300000\ty_inicial = -52.910000\n",
      "x: -0.400000\ty_inicial = -53.840000\n",
      "x: -0.500000\ty_inicial = -54.750000\n",
      "x: -0.600000\ty_inicial = -55.640000\n",
      "x: -0.700000\ty_inicial = -56.510000\n",
      "x: -0.800000\ty_inicial = -57.360000\n",
      "x: -0.900000\ty_inicial = -58.190000\n",
      "x: -1.000000\ty_inicial = -59.000000\n",
      "x: -1.100000\ty_inicial = -59.790000\n",
      "x: -1.200000\ty_inicial = -60.560000\n",
      "x: -1.300000\ty_inicial = -61.310000\n",
      "x: -1.400000\ty_inicial = -62.040000\n",
      "x: -1.500000\ty_inicial = -62.750000\n",
      "x: -1.600000\ty_inicial = -63.440000\n",
      "x: -1.700000\ty_inicial = -64.110000\n",
      "x: -1.800000\ty_inicial = -64.760000\n",
      "x: -1.900000\ty_inicial = -65.390000\n",
      "x: -2.000000\ty_inicial = -66.000000\n",
      "x: -2.100000\ty_inicial = -66.590000\n",
      "x: -2.200000\ty_inicial = -67.160000\n",
      "x: -2.300000\ty_inicial = -67.710000\n",
      "x: -2.400000\ty_inicial = -68.240000\n",
      "x: -2.500000\ty_inicial = -68.750000\n",
      "x: -2.600000\ty_inicial = -69.240000\n",
      "x: -2.700000\ty_inicial = -69.710000\n",
      "x: -2.800000\ty_inicial = -70.160000\n",
      "x: -2.900000\ty_inicial = -70.590000\n",
      "x: -3.000000\ty_inicial = -71.000000\n",
      "x: -3.100000\ty_inicial = -71.390000\n",
      "x: -3.200000\ty_inicial = -71.760000\n",
      "x: -3.300000\ty_inicial = -72.110000\n",
      "x: -3.400000\ty_inicial = -72.440000\n",
      "x: -3.500000\ty_inicial = -72.750000\n",
      "x: -3.600000\ty_inicial = -73.040000\n",
      "x: -3.700000\ty_inicial = -73.310000\n",
      "x: -3.800000\ty_inicial = -73.560000\n",
      "x: -3.900000\ty_inicial = -73.790000\n",
      "x: -4.000000\ty_inicial = -74.000000\n",
      "x: -4.100000\ty_inicial = -74.190000\n",
      "x: -4.200000\ty_inicial = -74.360000\n",
      "x: -4.300000\ty_inicial = -74.510000\n",
      "x: -4.400000\ty_inicial = -74.640000\n",
      "x: -4.500000\ty_inicial = -74.750000\n",
      "x: -4.600000\ty_inicial = -74.840000\n",
      "x: -4.700000\ty_inicial = -74.910000\n",
      "x: -4.800000\ty_inicial = -74.960000\n",
      "x: -4.900000\ty_inicial = -74.990000\n",
      "x: -5.000000\ty_inicial = -75.000000\n",
      "Número de iteraciones necesarias: 66\n",
      "-4.999999999999998\n",
      "\n",
      "======================================\n",
      "\n",
      "x: 0.000000\ty_inicial = -50.000000\n",
      "x: -1.000000\ty_inicial = -59.000000\n",
      "x: -2.000000\ty_inicial = -66.000000\n",
      "x: -3.000000\ty_inicial = -71.000000\n",
      "x: -4.000000\ty_inicial = -74.000000\n",
      "x: -5.000000\ty_inicial = -75.000000\n",
      "Número de iteraciones necesarias: 13\n",
      "-5.0\n"
     ]
    }
   ],
   "source": [
    "def minimo(f, args=(), x_inicial=1, variacion=1):\n",
    "    x = x_inicial\n",
    "    y_inicial = f(x, *args)\n",
    "    \n",
    "    n_iteracion = 1\n",
    "    \n",
    "    while(math.fabs(variacion) > 0.00001):\n",
    "        y_siguiente = f(x+variacion, *args)\n",
    "        if (y_siguiente > y_inicial):  # Si no disminuye, cambia de dirección a un paso menor\n",
    "            variacion *= -1\n",
    "            variacion /= 10  # Podrían unirse y hacer la operación /= -10 \n",
    "        else:\n",
    "            y_inicial = y_siguiente  # Disminuye\n",
    "            x += variacion\n",
    "            print(\"x: %f\\ty_inicial = %f\" % (x, y_inicial))\n",
    "        n_iteracion += 1\n",
    "        \n",
    "    print(\"Número de iteraciones necesarias: %d\" % n_iteracion)\n",
    "    return x\n",
    "\n",
    "    \n",
    "# Función\n",
    "f = lambda x: x**2 + 10*x -50\n",
    "\n",
    "# Lo calculamos con una variación 1\n",
    "print(minimo(f))\n",
    "\n",
    "print(\"\\n======================================\\n\")\n",
    "\n",
    "# Lo calculamos con una varación 10\n",
    "print(minimo(f, variacion=10))  # Menos iteraciones necesarias y más preciso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta implementación sólo calcula mínimos locales y está bastante limitada ya que debemos controlar la variación en $x$ de antemano.\n",
    "\n",
    "Si tenemos funciones simples (con una incógnita) podemos optar por resolverlas con los pasos a mano usando Sympy o con una implementación controlada en C porque será más eficiente. \n",
    "\n",
    "### A mano\n",
    "Para hallar los máximos o mínimos de una función $f(x) = x^2 + 10x -50$:\n",
    "\n",
    "1. La derivamos: $f'(x) = 2x + 10$\n",
    "2. La igualamos a 0 y resolvemos $x$: $$0 = 2x + 10$$ $$-2x = 10$$ $$-x = \\frac{10}{2}$$ $$x = -5$$\n",
    "3. Ahora tenemos el valor de $x$ con el que obtenemos el mínimo de $y$ en la función: $$f(-5) = (-5)^2 + 10 \\cdot -5 - 50 = -75$$\n",
    "\n",
    "> En este caso obtenemos el mínimo, pero si hubiéramos tenido la ecuación $f(x) = -x^2 + 10x -50$ hubiéramos obtenido el máximo ya que la parábola hubiera sido convexa.\n",
    "\n",
    "___________________________________________________\n",
    "\n",
    "## Descenso por gradiente\n",
    "La implementación de búsqueda de mínimos anterior en Python mostraba como encontrar el mínimo de una función modificando el valor de $x$ ya sea yendo hacia la izquierda (disminuyendo) o hacia la derecha (aumentando).\n",
    "\n",
    "Podemos usar la pendiente de la tangente en el punto inicial de $(x, y)$ de la función para saber si tenemos que disminuir o aumentar. Si la pendiente es positiva tendremos que disminuir y viceversa, como se muestra en la siguiente imagen:\n",
    "\n",
    "![Pendientes descenso gradiente](https://s20.postimg.org/f9dt0fwjx/pendientes_descenso_gradiente.png)\n",
    "\n",
    "Entonces tendríamos la expresión: $$x_{nuevo} = x_{anterior} + −y′$$\n",
    "\n",
    "Observa que la nueva $x$ sería la anterior más la inversa de la derivada de $y$ debido a que si la pendiente es positiva disminuimos y si es negativa aumentamos: siempre vamos en contra del valor de la pendiente, por eso la inversión.\n",
    "\n",
    "_____________________________________________\n",
    "\n",
    "Veamos un ejemplo:\n",
    "\n",
    "$$y = 5x^2 − 7x − 13$$\n",
    "$$y' = 10x - 7$$\n",
    "\n",
    "Como $x$ inicia en 1, luego: $$x_{nuevo} = 1 - (10x - 7)$$\n",
    "                             $$x_{nuevo} = 2$$\n",
    "                             \n",
    "Si calculamos los 20 primeros valores de X para la tabla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tx =          1.000000 \t\ty =                -15.000000 \n",
      "\t\tx =         -2.000000 \t\ty =                 21.000000 \n",
      "\t\tx =         25.000000 \t\ty =               2937.000000 \n",
      "\t\tx =       -218.000000 \t\ty =             239133.000000 \n",
      "\t\tx =       1969.000000 \t\ty =           19371009.000000 \n",
      "\t\tx =     -17714.000000 \t\ty =         1569052965.000000 \n",
      "\t\tx =     159433.000000 \t\ty =       127093291401.000000 \n",
      "\t\tx =   -1434890.000000 \t\ty =     10294556604717.000000 \n",
      "\t\tx =   12914017.000000 \t\ty =    833859084983313.000000 \n",
      "\t\tx = -116226146.000000 \t\ty =  67542585883649584.000000 \n"
     ]
    }
   ],
   "source": [
    "from scipy.misc import derivative\n",
    "\n",
    "# Dada la función\n",
    "f = lambda x: 5*x**2 - 7*x - 13\n",
    "\n",
    "x_anterior = 1\n",
    "\n",
    "for _ in range(10):\n",
    "    x = x_anterior\n",
    "    y = f(x)\n",
    "    print(\"\\t\\tx = %17f \\t\\ty = %25f \" % (x_anterior, y))\n",
    "    x_anterior = x_anterior - derivative(f, x_anterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor de X se dispara, se vuelve progresivamente extremo hacía la izquierda o derecha. Sucede algo parecido a la siguiente animación: \n",
    "\n",
    "![Descenso por gradiente divergente](https://s20.postimg.org/jg7u7entp/diverging_gradient_descent.gif)\n",
    "\n",
    "\n",
    "Para arreglarlo, se agrega una constante a la expresión, quedando así:\n",
    "$$x_{nuevo} = x_{anterior} + \\alpha \\cdot −y′$$\n",
    "donde $\\alpha$ es una constante muy pequeña. Con esto nos aseguramos que los números no se disparan. \n",
    "\n",
    "> La constante debe ser lo suficientemente pequeña para que no suceda el comportamiento de la animación anterior, en la cual la constante es 0.05, pero no lo suficiente para la escala de la curva en la gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tx = 1.000000\t\ty = -15.000000 \n",
      "\t\t\tx = 0.850000\t\ty = -15.337500 \n",
      "\t\t\tx = 0.775000\t\ty = -15.421875 \n",
      "\t\t\tx = 0.737500\t\ty = -15.442969 \n",
      "\t\t\tx = 0.718750\t\ty = -15.448242 \n",
      "\t\t\tx = 0.709375\t\ty = -15.449561 \n",
      "\t\t\tx = 0.704688\t\ty = -15.449890 \n",
      "\t\t\tx = 0.702344\t\ty = -15.449973 \n",
      "\t\t\tx = 0.701172\t\ty = -15.449993 \n",
      "\t\t\tx = 0.700586\t\ty = -15.449998 \n",
      "\t\t\tx = 0.700293\t\ty = -15.450000 \n",
      "\t\t\tx = 0.700146\t\ty = -15.450000 \n",
      "\t\t\tx = 0.700073\t\ty = -15.450000 \n",
      "\t\t\tx = 0.700037\t\ty = -15.450000 \n",
      "\t\t\tx = 0.700018\t\ty = -15.450000 \n",
      "\t\t\tx = 0.700009\t\ty = -15.450000 \n",
      "\t\t\tx = 0.700005\t\ty = -15.450000 \n",
      "\t\t\tx = 0.700002\t\ty = -15.450000 \n",
      "\t\t\tx = 0.700001\t\ty = -15.450000 \n",
      "\t\t\tx = 0.700001\t\ty = -15.450000 \n",
      "\t\t\tx = 0.700000\t\ty = -15.450000 \n",
      "\t\t\tx = 0.700000\t\ty = -15.450000 \n",
      "\t\t\tx = 0.700000\t\ty = -15.450000 \n",
      "\t\t\tx = 0.700000\t\ty = -15.450000 \n",
      "\t\t\tx = 0.700000\t\ty = -15.450000 \n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "x_anterior = 1\n",
    "\n",
    "for _ in range(25):\n",
    "    x = x_anterior\n",
    "    y = f(x)\n",
    "    print(\"\\t\\t\\tx = %f\\t\\ty = %f \" % (x, y))\n",
    "    # Redondeamos porque el método de scipy no es completamente fino\n",
    "    x_anterior = x_anterior - alpha * derivative(f, x_anterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este método se le conoce como el descenso del gradiente y se expresa así:\n",
    "$$x_{nuevo} = x_{anterior} − \\alpha \\cdot f′(x_{anterior})$$\n",
    "\n",
    "#### Formalmente:\n",
    "$$x_{n+1} = x_n − \\alpha \\cdot f′(x_n)$$\n",
    "\n",
    "#### Representación gráfica:\n",
    "\n",
    "![Descenso por gradiente](https://s20.postimg.org/6miz5cu8t/descent_gradient_animation.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Fuentes:\n",
    "- [Redes neuronales parte 1 - Rafael Alberto Moreno Parra](https://openlibra.com/es/book/redes-neuronales-parte-1)\n",
    "- https://glowingpython.blogspot.com.es/2011/04/how-to-find-minimum-of-function-using.html\n",
    "- https://www.cs.toronto.edu/~frossard/post/linear_regression/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
